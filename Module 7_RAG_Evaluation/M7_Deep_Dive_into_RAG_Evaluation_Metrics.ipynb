{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8890484b6c3e4018907b96b026510712":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a1982c87e18425a97c43a61c18f928b","IPY_MODEL_d7e48662099b409baeb15177af124bb5","IPY_MODEL_d3d8515a3b194fb3b1fdc820607a00bf"],"layout":"IPY_MODEL_ce0f9b8f431246da93ebbe3c5cb8b026"}},"0a1982c87e18425a97c43a61c18f928b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28c6583c344341599988c3dad3070cc8","placeholder":"​","style":"IPY_MODEL_9d4be022d51847e8a1ccd0a9eb885de2","value":"Evaluating: 100%"}},"d7e48662099b409baeb15177af124bb5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7614ca4667f948ccba8f980a1ae4722d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab7499442d7648168ca9415bda596e05","value":1}},"d3d8515a3b194fb3b1fdc820607a00bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad467cc9f9884950ada71fbb95cfccbd","placeholder":"​","style":"IPY_MODEL_c5bd0a78f28749e39a63421f0da20446","value":" 1/1 [00:03&lt;00:00,  3.12s/it]"}},"ce0f9b8f431246da93ebbe3c5cb8b026":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28c6583c344341599988c3dad3070cc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d4be022d51847e8a1ccd0a9eb885de2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7614ca4667f948ccba8f980a1ae4722d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab7499442d7648168ca9415bda596e05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad467cc9f9884950ada71fbb95cfccbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5bd0a78f28749e39a63421f0da20446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Build a Simple RAG System"],"metadata":{"id":"jbw4wHV4zlKj"}},{"cell_type":"markdown","source":["## Install OpenAI, and LangChain dependencies"],"metadata":{"id":"4vtFl39Ofu_8"}},{"cell_type":"code","source":["!pip install langchain==0.3.10\n","!pip install langchain-openai==0.2.12\n","!pip install langchain-community==0.3.11"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"527c6d32-ab83-4720-86c9-19d9aedcbb1a","id":"LVX6450Lfu_9","executionInfo":{"status":"ok","timestamp":1734095711061,"user_tz":-330,"elapsed":39827,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain==0.3.10 in /usr/local/lib/python3.10/dist-packages (0.3.10)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (3.11.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (4.0.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (0.3.22)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (0.3.2)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (0.1.147)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (2.10.3)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.10) (9.0.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.18.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.10) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.10) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.10) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.10) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.10) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (3.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.2.2)\n","Collecting langchain-openai==0.2.12\n","  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.2.12) (0.3.22)\n","Collecting openai<2.0.0,>=1.55.3 (from langchain-openai==0.2.12)\n","  Downloading openai-1.57.3-py3-none-any.whl.metadata (24 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.1.147)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (24.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.10.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (9.0.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.66.6)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.2.3)\n","Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.57.3-py3-none-any.whl (390 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.2/390.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.54.5\n","    Uninstalling openai-1.54.5:\n","      Successfully uninstalled openai-1.54.5\n","Successfully installed langchain-openai-0.2.12 openai-1.57.3 tiktoken-0.8.0\n","Collecting langchain-community==0.3.11\n","  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.11) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.11) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.11) (3.11.10)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.11)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.11)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Collecting langchain<0.4.0,>=0.3.11 (from langchain-community==0.3.11)\n","  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langchain-core<0.4.0,>=0.3.24 (from langchain-community==0.3.11)\n","  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.11) (0.1.147)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.11) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.11)\n","  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.11) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.11) (9.0.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.18.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n","  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.3.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.10.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.0)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.11) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.27.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.2.2)\n","Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n","Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.22\n","    Uninstalling langchain-core-0.3.22:\n","      Successfully uninstalled langchain-core-0.3.22\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.3.10\n","    Uninstalling langchain-0.3.10:\n","      Successfully uninstalled langchain-0.3.10\n","Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.11 langchain-community-0.3.11 langchain-core-0.3.24 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"]}]},{"cell_type":"markdown","source":["## Install Chroma Vector DB and LangChain wrapper"],"metadata":{"id":"bwUBYHjPfu_-"}},{"cell_type":"code","source":["!pip install langchain-chroma==0.1.4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"52ad0aa7-bfde-408e-9bb7-8ed0471bb87b","id":"p30SmCgTfu__","executionInfo":{"status":"ok","timestamp":1734095745921,"user_tz":-330,"elapsed":34862,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-chroma==0.1.4\n","  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n","Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma==0.1.4)\n","  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n","Collecting fastapi<1,>=0.95.2 (from langchain-chroma==0.1.4)\n","  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: langchain-core<0.4,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.4) (0.3.24)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.4) (1.26.4)\n","Collecting build>=1.0.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.10.3)\n","Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n","Collecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.12.2)\n","Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.28.2)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.28.2)\n","Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.20.3)\n","Collecting pypika>=0.48.9 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.66.6)\n","Collecting overrides>=7.3.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (6.4.5)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.68.1)\n","Collecting bcrypt>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.15.1)\n","Collecting kubernetes>=28.1.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (9.0.0)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (6.0.2)\n","Collecting mmh3>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.10.12)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (13.9.4)\n","Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.4)\n","  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (1.33)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (0.1.147)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (24.2)\n","Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.2.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (3.0.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.32.3)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.2.3)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (1.0.0)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.25.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.13.1)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.15)\n","Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (8.5.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.66.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n","Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.17.0)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.27.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.26.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.5.4)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.0.1)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2024.10.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.4.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.6.1)\n","Downloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n","Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n","Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n","Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n","Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n","Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n","Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n","Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=b44d520b4d55672cb7230f8a62bd06693ccfe27b9283d12b6b4c7bcb2b50a4b1\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","  Attempting uninstall: opentelemetry-api\n","    Found existing installation: opentelemetry-api 1.28.2\n","    Uninstalling opentelemetry-api-1.28.2:\n","      Successfully uninstalled opentelemetry-api-1.28.2\n","  Attempting uninstall: opentelemetry-semantic-conventions\n","    Found existing installation: opentelemetry-semantic-conventions 0.49b2\n","    Uninstalling opentelemetry-semantic-conventions-0.49b2:\n","      Successfully uninstalled opentelemetry-semantic-conventions-0.49b2\n","  Attempting uninstall: opentelemetry-sdk\n","    Found existing installation: opentelemetry-sdk 1.28.2\n","    Uninstalling opentelemetry-sdk-1.28.2:\n","      Successfully uninstalled opentelemetry-sdk-1.28.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 langchain-chroma-0.1.4 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.1 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.3 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.3 websockets-14.1\n"]}]},{"cell_type":"markdown","source":["## Install RAG Eval Libraries"],"metadata":{"id":"ZNg9rKKVa3DJ"}},{"cell_type":"code","source":["!pip install ragas==0.2.8\n","!pip install deepeval==1.4.7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0jQ2rswHa5-o","outputId":"75908687-de73-4826-b83e-27159465f61d","executionInfo":{"status":"ok","timestamp":1734095775630,"user_tz":-330,"elapsed":29711,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ragas==0.2.8\n","  Downloading ragas-0.2.8-py3-none-any.whl.metadata (9.1 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (1.26.4)\n","Collecting datasets (from ragas==0.2.8)\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (0.8.0)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (0.3.11)\n","Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (0.3.24)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (0.3.11)\n","Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (0.2.12)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (1.6.0)\n","Collecting appdirs (from ragas==0.2.8)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (2.10.3)\n","Requirement already satisfied: openai>1 in /usr/local/lib/python3.10/dist-packages (from ragas==0.2.8) (1.57.3)\n","Collecting pysbd>=0.3.4 (from ragas==0.2.8)\n","  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.2.8) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.2.8) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.2.8) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.2.8) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.2.8) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.2.8) (4.66.6)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.2.8) (4.12.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ragas==0.2.8) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ragas==0.2.8) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas==0.2.8)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (2.32.3)\n","Collecting xxhash (from datasets->ragas==0.2.8)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->ragas==0.2.8)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas==0.2.8)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (3.11.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (0.26.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.2.8) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.2.8) (2.0.36)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.2.8) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.2.8) (0.3.2)\n","Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.2.8) (0.1.147)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.2.8) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core->ragas==0.2.8) (1.33)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas==0.2.8) (0.6.7)\n","Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas==0.2.8) (0.4.0)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas==0.2.8) (2.7.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas==0.2.8) (2024.9.11)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.2.8) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.2.8) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.2.8) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.2.8) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.2.8) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.2.8) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.2.8) (1.18.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.2.8) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.2.8) (1.2.2)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.2.8) (3.23.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.2.8) (0.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.2.8) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.2.8) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.2.8) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas==0.2.8) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain->ragas==0.2.8) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain->ragas==0.2.8) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas==0.2.8) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->ragas==0.2.8) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->ragas==0.2.8) (2.2.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas==0.2.8) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas==0.2.8) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas==0.2.8) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas==0.2.8) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.2.8) (1.17.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.2.8) (1.0.0)\n","Downloading ragas-0.2.8-py3-none-any.whl (173 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: appdirs, xxhash, pysbd, fsspec, dill, multiprocess, datasets, ragas\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed appdirs-1.4.4 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 pysbd-0.3.4 ragas-0.2.8 xxhash-3.5.0\n","Collecting deepeval==1.4.7\n","  Downloading deepeval-1.4.7-py3-none-any.whl.metadata (977 bytes)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (4.66.6)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (8.3.4)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (0.9.0)\n","Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (0.15.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (13.9.4)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (5.29.1)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (2.10.3)\n","Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (2.19.2)\n","Collecting pytest-repeat (from deepeval==1.4.7)\n","  Downloading pytest_repeat-0.9.3-py3-none-any.whl.metadata (4.9 kB)\n","Collecting pytest-xdist (from deepeval==1.4.7)\n","  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\n","Collecting portalocker (from deepeval==1.4.7)\n","  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (0.3.11)\n","Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (0.3.24)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (0.2.12)\n","Requirement already satisfied: ragas in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (0.2.8)\n","Collecting docx2txt~=0.8 (from deepeval==1.4.7)\n","  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-metadata>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from deepeval==1.4.7) (8.5.0)\n","Collecting tenacity~=8.4.1 (from deepeval==1.4.7)\n","  Downloading tenacity-8.4.2-py3-none-any.whl.metadata (1.2 kB)\n","Collecting opentelemetry-api~=1.24.0 (from deepeval==1.4.7)\n","  Downloading opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n","Collecting opentelemetry-sdk~=1.24.0 (from deepeval==1.4.7)\n","  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc~=1.24.0 (from deepeval==1.4.7)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting grpcio~=1.63.0 (from deepeval==1.4.7)\n","  Downloading grpcio-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.0.2->deepeval==1.4.7) (3.21.0)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api~=1.24.0->deepeval==1.4.7) (1.2.15)\n","Collecting importlib-metadata>=6.0.2 (from deepeval==1.4.7)\n","  Downloading importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval==1.4.7) (1.66.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval==1.4.7)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n","Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval==1.4.7)\n","  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting protobuf (from deepeval==1.4.7)\n","  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk~=1.24.0->deepeval==1.4.7)\n","  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk~=1.24.0->deepeval==1.4.7) (4.12.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval==1.4.7) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval==1.4.7) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval==1.4.7) (3.11.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval==1.4.7) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval==1.4.7) (0.3.2)\n","Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval==1.4.7) (0.1.147)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval==1.4.7) (1.26.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core->deepeval==1.4.7) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core->deepeval==1.4.7) (24.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepeval==1.4.7) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepeval==1.4.7) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval==1.4.7) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval==1.4.7) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval==1.4.7) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval==1.4.7) (2024.8.30)\n","Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from langchain-openai->deepeval==1.4.7) (1.57.3)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai->deepeval==1.4.7) (0.8.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval==1.4.7) (1.2.2)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval==1.4.7) (2.0.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval==1.4.7) (1.5.0)\n","Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval==1.4.7) (2.2.1)\n","Collecting execnet>=2.1 (from pytest-xdist->deepeval==1.4.7)\n","  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval==1.4.7) (3.2.0)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval==1.4.7) (0.3.11)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval==1.4.7) (1.6.0)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval==1.4.7) (1.4.4)\n","Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval==1.4.7) (0.3.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->deepeval==1.4.7) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->deepeval==1.4.7) (2.18.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer->deepeval==1.4.7) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->deepeval==1.4.7) (1.5.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval==1.4.7) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval==1.4.7) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval==1.4.7) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval==1.4.7) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval==1.4.7) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval==1.4.7) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval==1.4.7) (1.18.3)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24.0->deepeval==1.4.7) (1.17.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval==1.4.7) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain->deepeval==1.4.7) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain->deepeval==1.4.7) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain->deepeval==1.4.7) (1.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->deepeval==1.4.7) (0.1.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai->deepeval==1.4.7) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai->deepeval==1.4.7) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai->deepeval==1.4.7) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai->deepeval==1.4.7) (1.3.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval==1.4.7) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval==1.4.7) (2024.9.11)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval==1.4.7) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval==1.4.7) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval==1.4.7) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval==1.4.7) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval==1.4.7) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval==1.4.7) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas->deepeval==1.4.7) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval==1.4.7) (0.26.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas->deepeval==1.4.7) (0.6.7)\n","Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas->deepeval==1.4.7) (0.4.0)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas->deepeval==1.4.7) (2.7.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval==1.4.7) (3.23.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval==1.4.7) (0.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain->deepeval==1.4.7) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain->deepeval==1.4.7) (0.14.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval==1.4.7) (1.0.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval==1.4.7) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval==1.4.7) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval==1.4.7) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas->deepeval==1.4.7) (1.17.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval==1.4.7) (1.0.0)\n","Downloading deepeval-1.4.7-py3-none-any.whl (461 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m461.1/461.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n","Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n","Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n","Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.4.2-py3-none-any.whl (28 kB)\n","Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n","Downloading pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\n","Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading execnet-2.1.1-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: docx2txt\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=bff999fb41a88fc6f53952fe29d538bf1bc9ab0126e6f2cfba387115833a88b0\n","  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n","Successfully built docx2txt\n","Installing collected packages: docx2txt, tenacity, protobuf, portalocker, opentelemetry-semantic-conventions, importlib-metadata, grpcio, execnet, pytest-xdist, pytest-repeat, opentelemetry-proto, opentelemetry-api, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-common, opentelemetry-exporter-otlp-proto-grpc, deepeval\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.1\n","    Uninstalling protobuf-5.29.1:\n","      Successfully uninstalled protobuf-5.29.1\n","  Attempting uninstall: opentelemetry-semantic-conventions\n","    Found existing installation: opentelemetry-semantic-conventions 0.50b0\n","    Uninstalling opentelemetry-semantic-conventions-0.50b0:\n","      Successfully uninstalled opentelemetry-semantic-conventions-0.50b0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.5.0\n","    Uninstalling importlib_metadata-8.5.0:\n","      Successfully uninstalled importlib_metadata-8.5.0\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.68.1\n","    Uninstalling grpcio-1.68.1:\n","      Successfully uninstalled grpcio-1.68.1\n","  Attempting uninstall: opentelemetry-proto\n","    Found existing installation: opentelemetry-proto 1.29.0\n","    Uninstalling opentelemetry-proto-1.29.0:\n","      Successfully uninstalled opentelemetry-proto-1.29.0\n","  Attempting uninstall: opentelemetry-api\n","    Found existing installation: opentelemetry-api 1.29.0\n","    Uninstalling opentelemetry-api-1.29.0:\n","      Successfully uninstalled opentelemetry-api-1.29.0\n","  Attempting uninstall: opentelemetry-sdk\n","    Found existing installation: opentelemetry-sdk 1.29.0\n","    Uninstalling opentelemetry-sdk-1.29.0:\n","      Successfully uninstalled opentelemetry-sdk-1.29.0\n","  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n","    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.29.0\n","    Uninstalling opentelemetry-exporter-otlp-proto-common-1.29.0:\n","      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.29.0\n","  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n","    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.29.0\n","    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.29.0:\n","      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.29.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-cloud-pubsub 2.27.1 requires opentelemetry-api>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-api 1.24.0 which is incompatible.\n","google-cloud-pubsub 2.27.1 requires opentelemetry-sdk>=1.27.0; python_version >= \"3.8\", but you have opentelemetry-sdk 1.24.0 which is incompatible.\n","opentelemetry-instrumentation 0.50b0 requires opentelemetry-semantic-conventions==0.50b0, but you have opentelemetry-semantic-conventions 0.45b0 which is incompatible.\n","opentelemetry-instrumentation-asgi 0.50b0 requires opentelemetry-semantic-conventions==0.50b0, but you have opentelemetry-semantic-conventions 0.45b0 which is incompatible.\n","opentelemetry-instrumentation-fastapi 0.50b0 requires opentelemetry-semantic-conventions==0.50b0, but you have opentelemetry-semantic-conventions 0.45b0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed deepeval-1.4.7 docx2txt-0.8 execnet-2.1.1 grpcio-1.63.2 importlib-metadata-7.0.0 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 portalocker-3.0.0 protobuf-4.25.5 pytest-repeat-0.9.3 pytest-xdist-3.6.1 tenacity-8.4.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["importlib_metadata"]},"id":"1a29537fe3c14759b7fc35d16e2e18a5"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Enter Open AI API Key"],"metadata":{"id":"EITC17hwfu__"}},{"cell_type":"code","source":["from getpass import getpass\n","\n","OPENAI_KEY = getpass('Enter Open AI API Key: ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0ef138d1-d440-4742-f430-70553130f4aa","id":"yEh2olNvfvAA","executionInfo":{"status":"ok","timestamp":1734095792300,"user_tz":-330,"elapsed":6664,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":1,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Open AI API Key: ··········\n"]}]},{"cell_type":"markdown","source":["## Setup Environment Variables"],"metadata":{"id":"pm_mx0v-fvAA"}},{"cell_type":"code","source":["import os\n","\n","os.environ['OPENAI_API_KEY'] = OPENAI_KEY"],"metadata":{"id":"Jhfb4gMUfvAC","executionInfo":{"status":"ok","timestamp":1734095793871,"user_tz":-330,"elapsed":316,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Open AI Embedding Models\n","\n","LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."],"metadata":{"id":"jiokYxD8fvAC"}},{"cell_type":"code","source":["from langchain_openai import OpenAIEmbeddings\n","\n","# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n","openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"],"metadata":{"id":"-On4AS0HfvAD","executionInfo":{"status":"ok","timestamp":1734095806085,"user_tz":-330,"elapsed":2699,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Loading and Processing the Data"],"metadata":{"id":"afzeN_WkHIz2"}},{"cell_type":"markdown","source":["### Get the dataset"],"metadata":{"id":"RA_-hzHbFeSP"}},{"cell_type":"code","source":["# if you can't download using the following code\n","# go to https://drive.google.com/file/d/1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb/view?usp=sharing download it\n","# manually upload it on colab\n","!gdown 1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb"],"metadata":{"id":"RZFMYH-yFhWn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00619159-fb81-4883-fbc3-7ab9d4c356ce","executionInfo":{"status":"ok","timestamp":1734095814389,"user_tz":-330,"elapsed":4661,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb\n","To: /content/rag_eval_docs.csv\n","\r  0% 0.00/2.66k [00:00<?, ?B/s]\r100% 2.66k/2.66k [00:00<00:00, 10.3MB/s]\n"]}]},{"cell_type":"markdown","source":["### Load and Process JSON Documents"],"metadata":{"id":"wMlxKZ_5jIdE"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('./rag_eval_docs.csv')\n","df"],"metadata":{"id":"RZ5y0NfzHPhg","colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"335d55de-e7bf-4b32-b496-f7bb1b4e8b05","executionInfo":{"status":"ok","timestamp":1734095814986,"user_tz":-330,"elapsed":598,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                              title  \\\n","0   1                   Machine Learning   \n","1   2                      Deep Learning   \n","2   3  Natural Language Processing (NLP)   \n","3   4                           Pyramids   \n","4   5                     Photosynthesis   \n","5   6                            Biology   \n","6   7                  Quantum Mechanics   \n","7   8                     Cryptocurrency   \n","8   9                   Renewable Energy   \n","9  10            Artificial Intelligence   \n","\n","                                             context  \n","0  Machine learning is a field of artificial inte...  \n","1  Deep learning is a subset of machine learning ...  \n","2  NLP is a branch of AI that enables computers t...  \n","3  Pyramids are ancient structures, often serving...  \n","4  Photosynthesis is the process plants use to co...  \n","5  Biology is the study of living organisms, cove...  \n","6  Quantum mechanics is a branch of physics that ...  \n","7  Cryptocurrency is a digital currency that uses...  \n","8  Renewable energy sources, such as solar and wi...  \n","9  Artificial intelligence refers to machines mim...  "],"text/html":["\n","  <div id=\"df-56c3c2ac-3fbb-411e-9d8d-0df72d635500\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Machine Learning</td>\n","      <td>Machine learning is a field of artificial inte...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Deep Learning</td>\n","      <td>Deep learning is a subset of machine learning ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Natural Language Processing (NLP)</td>\n","      <td>NLP is a branch of AI that enables computers t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Pyramids</td>\n","      <td>Pyramids are ancient structures, often serving...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Photosynthesis</td>\n","      <td>Photosynthesis is the process plants use to co...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>Biology</td>\n","      <td>Biology is the study of living organisms, cove...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>Quantum Mechanics</td>\n","      <td>Quantum mechanics is a branch of physics that ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>Cryptocurrency</td>\n","      <td>Cryptocurrency is a digital currency that uses...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>Renewable Energy</td>\n","      <td>Renewable energy sources, such as solar and wi...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>Artificial Intelligence</td>\n","      <td>Artificial intelligence refers to machines mim...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56c3c2ac-3fbb-411e-9d8d-0df72d635500')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-56c3c2ac-3fbb-411e-9d8d-0df72d635500 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-56c3c2ac-3fbb-411e-9d8d-0df72d635500');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b6d1016f-de74-46cd-9b2f-a51cbb05cca3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6d1016f-de74-46cd-9b2f-a51cbb05cca3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b6d1016f-de74-46cd-9b2f-a51cbb05cca3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_92def8d4-269d-4254-b097-9ca0e5c859be\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_92def8d4-269d-4254-b097-9ca0e5c859be button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Renewable Energy\",\n          \"Deep Learning\",\n          \"Biology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.\",\n          \"Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.\",\n          \"Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["docs = df.to_dict(orient='records')\n","docs[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wE4l0DG7tpTI","outputId":"3b151538-c291-4c16-ee09-c3cabd223152","executionInfo":{"status":"ok","timestamp":1734095814986,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'id': 1,\n","  'title': 'Machine Learning',\n","  'context': 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.'},\n"," {'id': 2,\n","  'title': 'Deep Learning',\n","  'context': 'Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.'},\n"," {'id': 3,\n","  'title': 'Natural Language Processing (NLP)',\n","  'context': 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from langchain.docstore.document import Document\n","processed_docs = []\n","\n","for doc in docs:\n","    metadata = {\n","        \"title\": doc['title'],\n","        \"id\": doc['id'],\n","    }\n","    data = doc['context']\n","    processed_docs.append(Document(page_content=data, metadata=metadata))\n","processed_docs[:3]"],"metadata":{"id":"yICyAF85h2DO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74cfef9f-072b-486b-b069-da1bf505af05","executionInfo":{"status":"ok","timestamp":1734095814986,"user_tz":-330,"elapsed":3,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'title': 'Machine Learning', 'id': 1}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.'),\n"," Document(metadata={'title': 'Deep Learning', 'id': 2}, page_content='Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.'),\n"," Document(metadata={'title': 'Natural Language Processing (NLP)', 'id': 3}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.')]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## Index Document Chunks and Embeddings in Vector DB\n","\n","Here we initialize a connection to a Chroma vector DB client, and also we want to save to disk, so we simply initialize the Chroma client and pass the directory where we want the data to be saved to."],"metadata":{"id":"Daqn6Hglw9Nk"}},{"cell_type":"code","source":["from langchain_chroma import Chroma\n","\n","# create vector DB of docs and embeddings - takes < 30s on Colab\n","chroma_db = Chroma.from_documents(documents=processed_docs,\n","                                  collection_name='my_db',\n","                                  embedding=openai_embed_model,\n","                                  # need to set the distance function to cosine else it uses euclidean by default\n","                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n","                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n","                                  persist_directory=\"./my_db\")"],"metadata":{"id":"EYjyZdCyw9Nl","executionInfo":{"status":"ok","timestamp":1734095818818,"user_tz":-330,"elapsed":2590,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-0qbbpjw9Nl"},"source":["### Load Vector DB from disk\n","\n","This is just to show once you have a vector database on disk you can just load and create a connection to it anytime"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"PI3ITuGZw9Nl","executionInfo":{"status":"ok","timestamp":1734095818819,"user_tz":-330,"elapsed":1,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"outputs":[],"source":["# load from disk\n","chroma_db = Chroma(persist_directory=\"./my_db\",\n","                   collection_name='my_db',\n","                   embedding_function=openai_embed_model)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Udsb8xyVw9Nl","outputId":"ec4fea0d-089d-4868-c2d3-a66403407680","executionInfo":{"status":"ok","timestamp":1734095819136,"user_tz":-330,"elapsed":1,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langchain_chroma.vectorstores.Chroma at 0x79c1c50e9c90>"]},"metadata":{},"execution_count":10}],"source":["chroma_db"]},{"cell_type":"markdown","source":["### Semantic Similarity based Retrieval\n","\n","We use simple cosine similarity here and retrieve the top 3 similar documents based on the user input query"],"metadata":{"id":"njfZOOVZxj1a"}},{"cell_type":"code","source":["similarity_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n","                                              search_kwargs={\"k\": 3, \"score_threshold\": 0.3})"],"metadata":{"id":"tV1l6HYdxj1b","executionInfo":{"status":"ok","timestamp":1734095819939,"user_tz":-330,"elapsed":1,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display, Markdown\n","\n","def display_docs(docs):\n","    for doc in docs:\n","        print('Metadata:', doc.metadata)\n","        print('Content Brief:')\n","        display(Markdown(doc.page_content))\n","        print()"],"metadata":{"id":"nUIJG_bDxj1c","executionInfo":{"status":"ok","timestamp":1734095822009,"user_tz":-330,"elapsed":489,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["query = \"what is AI?\"\n","top_docs = similarity_retriever.invoke(query)\n","display_docs(top_docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"PIh4xGv2xj1c","outputId":"15871aaa-e3d9-41e3-d5cf-086cd27e8e5b","executionInfo":{"status":"ok","timestamp":1734095824222,"user_tz":-330,"elapsed":1206,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Metadata: {'id': 10, 'title': 'Artificial Intelligence'}\n","Content Brief:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning."},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Metadata: {'id': 3, 'title': 'Natural Language Processing (NLP)'}\n","Content Brief:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services."},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Metadata: {'id': 1, 'title': 'Machine Learning'}\n","Content Brief:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition."},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["query = \"how do plants survive?\"\n","top_docs = similarity_retriever.invoke(query)\n","display_docs(top_docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":117},"id":"S_PXFMcJxuyO","outputId":"784ca418-9a0f-41da-a96f-cf7d546db820","executionInfo":{"status":"ok","timestamp":1734095825289,"user_tz":-330,"elapsed":556,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Metadata: {'id': 5, 'title': 'Photosynthesis'}\n","Content Brief:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen."},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","source":["## Build the RAG Pipeline"],"metadata":{"id":"gQFWv7YUyVII"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n","                Answer the following question using only the following pieces of retrieved context.\n","                If the answer is not in the context, do not make up answers, just say that you don't know.\n","                Keep the answer to the point based on the information from the context.\n","\n","                Question:\n","                {question}\n","\n","                Context:\n","                {context}\n","\n","                Answer:\n","            \"\"\"\n","\n","rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"],"metadata":{"id":"PHOrfGXKyVIJ","executionInfo":{"status":"ok","timestamp":1734095826589,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from langchain_core.runnables import RunnablePassthrough\n","from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.runnables import RunnableLambda\n","from operator import itemgetter\n","\n","\n","chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","src_rag_response_chain = (\n","    {\n","        \"context\": (itemgetter('context')\n","                        |\n","                    RunnableLambda(format_docs)),\n","        \"question\": itemgetter(\"question\")\n","    }\n","        |\n","    rag_prompt_template\n","        |\n","    chatgpt\n","        |\n","    StrOutputParser()\n",")\n","\n","rag_chain_w_sources = (\n","    {\n","        \"context\": similarity_retriever,\n","        \"question\": RunnablePassthrough()\n","    }\n","        |\n","    RunnablePassthrough.assign(response=src_rag_response_chain)\n",")"],"metadata":{"id":"KmWeCB4yyVIJ","executionInfo":{"status":"ok","timestamp":1734095828216,"user_tz":-330,"elapsed":454,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["query = \"What is AI?\"\n","result = rag_chain_w_sources.invoke(query)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"facb3195-a81b-49b2-c230-8a9c0d242f77","id":"xvj_eGIWyVIJ","executionInfo":{"status":"ok","timestamp":1734095830720,"user_tz":-330,"elapsed":1333,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["query = \"How do plants survive?\"\n","result = rag_chain_w_sources.invoke(query)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXtezDlZzadt","outputId":"0f780c0a-f3ae-413f-f773-4bc9a384b82b","executionInfo":{"status":"ok","timestamp":1734095832413,"user_tz":-330,"elapsed":786,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 5, 'title': 'Photosynthesis'}, page_content='Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.')],\n"," 'question': 'How do plants survive?',\n"," 'response': 'Plants survive by using photosynthesis to convert sunlight into energy, producing glucose and releasing oxygen as a byproduct.'}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# Retriever Evaluation Metrics\n","\n","![](https://i.imgur.com/5S4FhMB.png)\n","\n","The retrieval process generally includes these steps:\n","\n","- Convert the initial input query into an embedding using an embedding model of your choice (e.g., OpenAI's `text-embedding-3` model).\n","- Conduct a vector search with the embedded input on a vector database that holds your vectorized knowledge base, retrieving the top-K most \"similar\" document chunks.\n","- Optionally user a Reranker to rerank the retrieved results\n","\n","\n","Key Metrics to Evaluate here include:\n","\n","- Contextual Precision\n","- Contextual Recall\n","- Contextual Relevancy"],"metadata":{"id":"MTTk1BaCBfYa"}},{"cell_type":"markdown","source":["## Contextual Precision\n","\n","The contextual precision metric measures your RAG pipeline's retriever by evaluating whether document chunks (nodes) in your `retrieval_context` that are relevant to the given `input` are ranked higher than irrelevant ones.\n","\n","`deepeval`'s contextual precision metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a judge.\n","\n","In `deepeval`, to use the ContextualPrecisionMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n","\n","- `input` : Input Query\n","- `actual_output` : Actual LLM Response (not used in the computation)\n","- `expected_output` : Expected LLM Response (ground truth answer)\n","- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n","\n","\n","![](https://i.imgur.com/oVwrRAU.png)\n","\n","\n","\n"],"metadata":{"id":"gQOoZNPzDdjY"}},{"cell_type":"code","source":["query = \"What is AI?\"\n","response = rag_chain_w_sources.invoke(query)\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deG08v9sF0pY","outputId":"8905b41c-2671-4a66-889c-eb7423d3343d","executionInfo":{"status":"ok","timestamp":1734095838031,"user_tz":-330,"elapsed":1400,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["### Example:"],"metadata":{"id":"FXisPv9hSbSL"}},{"cell_type":"code","source":["retrieved_context = [doc.page_content for doc in response['context']]\n","retrieved_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v9cW2lv1IzIx","outputId":"d9fdaa17-172c-4026-971a-dc418ed41c82","executionInfo":{"status":"ok","timestamp":1734095838362,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\"\"\""],"metadata":{"id":"Bm8St8H7F5nS","executionInfo":{"status":"ok","timestamp":1734095840510,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["new_context = ['Machine Learning is the study of algorithms which learn with more data',\n","               'AI is known as Artificial Intelligence'] + retrieved_context\n","new_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOhNhwphJEfU","outputId":"9504fe9d-340b-4cdd-da6a-71d88d96ee49","executionInfo":{"status":"ok","timestamp":1734095841851,"user_tz":-330,"elapsed":323,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Machine Learning is the study of algorithms which learn with more data',\n"," 'AI is known as Artificial Intelligence',\n"," \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["from deepeval.test_case import LLMTestCase\n","from deepeval.metrics import ContextualPrecisionMetric\n","from deepeval import evaluate\n","\n","test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n","    expected_output=human_answer,\n","    retrieval_context=new_context\n",")\n","\n","metric = ContextualPrecisionMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    include_reason=True,\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2Urkt1YHIuK8","outputId":"8736b357-0964-4c4c-b00c-d008ea353895","executionInfo":{"status":"ok","timestamp":1734095853038,"user_tz":-330,"elapsed":9005,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/deepeval/__init__.py:49: UserWarning: You are using deepeval version 1.4.7, however version 2.0.5 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:07,  7.52s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Contextual Precision Verbose Logs\n","**************************************************\n","\n","Verdicts:\n","[\n","    {\n","        \"verdict\": \"no\",\n","        \"reason\": \"The context discusses Machine Learning, which is a subfield of AI, but does not directly relate to the definition or applications of AI needed for the expected output.\"\n","    },\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": \"This context provides the definition 'AI is known as Artificial Intelligence,' which is part of the expected output.\"\n","    },\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": \"The context describes AI and its applications, directly contributing to understanding AI as 'applications like virtual assistants, robotics, and autonomous vehicles,' aligning with the expected output.\"\n","    },\n","    {\n","        \"verdict\": \"no\",\n","        \"reason\": \"The context is about NLP, a branch of AI, but does not directly contribute to the general definition and applications of AI required in the expected output.\"\n","    },\n","    {\n","        \"verdict\": \"no\",\n","        \"reason\": \"This context focuses on Machine Learning, a part of AI, but does not address the broader definition or applications of AI itself needed for the expected output.\"\n","    }\n","]\n"," \n","Score: 0.5833333333333333\n","Reason: The score is 0.58 because the first node in the retrieval context discusses 'Machine Learning, which is a subfield of AI, but does not directly relate to the definition or applications of AI needed for the expected output,' leading to a lower precision score. However, the second and third nodes provide relevant information, with the second node offering the definition 'AI is known as Artificial Intelligence' and the third node describing AI applications such as 'virtual assistants, robotics, and autonomous vehicles,' which contribute positively to the score. The presence of irrelevant nodes about 'NLP, a branch of AI, but does not directly contribute to the general definition and applications of AI' and 'Machine Learning, a part of AI, but does not address the broader definition or applications of AI' further impacts the overall score.\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Contextual Precision (score: 0.5833333333333333, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.58 because the first node in the retrieval context discusses 'Machine Learning, which is a subfield of AI, but does not directly relate to the definition or applications of AI needed for the expected output,' leading to a lower precision score. However, the second and third nodes provide relevant information, with the second node offering the definition 'AI is known as Artificial Intelligence' and the third node describing AI applications such as 'virtual assistants, robotics, and autonomous vehicles,' which contribute positively to the score. The presence of irrelevant nodes about 'NLP, a branch of AI, but does not directly contribute to the general definition and applications of AI' and 'Machine Learning, a part of AI, but does not address the broader definition or applications of AI' further impacts the overall score., error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\n","  - context: None\n","  - retrieval context: ['Machine Learning is the study of algorithms which learn with more data', 'AI is known as Artificial Intelligence', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Contextual Precision: 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00qrXrl9JY06","outputId":"07ae6595-2dcc-4908-9d5b-7fd5da06e859","executionInfo":{"status":"ok","timestamp":1734095863827,"user_tz":-330,"elapsed":413,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 0.5833333333333333\n","Reason: The score is 0.58 because the first node in the retrieval context discusses 'Machine Learning, which is a subfield of AI, but does not directly relate to the definition or applications of AI needed for the expected output,' leading to a lower precision score. However, the second and third nodes provide relevant information, with the second node offering the definition 'AI is known as Artificial Intelligence' and the third node describing AI applications such as 'virtual assistants, robotics, and autonomous vehicles,' which contribute positively to the score. The presence of irrelevant nodes about 'NLP, a branch of AI, but does not directly contribute to the general definition and applications of AI' and 'Machine Learning, a part of AI, but does not address the broader definition or applications of AI' further impacts the overall score.\n"]}]},{"cell_type":"markdown","source":["## Contextual Recall\n","\n","The contextual recall metric measures the quality of your RAG pipeline's retriever by evaluating the extent of which the `retrieval_context` aligns with the `expected_output`.\n","\n","`deepeval`'s contextual recall metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n","\n","In `deepeval`, to use the ContextualRecallMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n","\n","- `input` : Input Query (not used in the computation)\n","- `actual_output` : Actual LLM Response (not used in the computation)\n","- `expected_output` : Expected LLM Response (ground truth answer)\n","- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n","\n","\n","![](https://i.imgur.com/PDbwuX5.png)\n","\n","\n","\n"],"metadata":{"id":"uTDmP7-dLRlp"}},{"cell_type":"code","source":["query = \"What is AI?\"\n","response = rag_chain_w_sources.invoke(query)\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2cc9da2-ca24-41f6-a7d0-53890dacb488","id":"VhnDaJvELRlq"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, including problem-solving and learning, with applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["### Example 1:"],"metadata":{"id":"SRdTNvgESiaC"}},{"cell_type":"code","source":["retrieved_context = [doc.page_content for doc in response['context']]\n","retrieved_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"76f5611a-9ed0-4120-dd20-abbfafef7221","id":"Uv7FKS6XLRlr"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\"\"\""],"metadata":{"id":"90_guzmVLRls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_context = ['NVIDIA makes chips for AI', 'AI is an acronym for Artificial Intellence']\n","new_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f522e7cd-e815-4634-a180-9e3347630fe1","id":"84eNVGrwLRlt"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['NVIDIA makes chips for AI', 'AI is an acronym for Artificial Intellence']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["from deepeval.test_case import LLMTestCase\n","from deepeval.metrics import ContextualRecallMetric\n","from deepeval import evaluate\n","\n","test_case1 = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n","    expected_output=human_answer,\n","    retrieval_context=retrieved_context\n",")\n","\n","test_case2 = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n","    expected_output=human_answer,\n","    retrieval_context=new_context\n",")\n","\n","metric = ContextualRecallMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    include_reason=True,\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case1, test_case2], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"267e8858-71f1-41a8-d27d-e80f5f635cd8","id":"Of-wta5OLRlt"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 2 test case(s) in parallel: |█████     | 50% (1/2) [Time Taken: 00:03,  3.36s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Contextual Recall Verbose Logs\n","**************************************************\n","\n","Verdicts:\n","[\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": \"The 1st node mentions 'AI includes applications like virtual assistants, robotics, and autonomous vehicles...'\"\n","    }\n","]\n"," \n","Score: 1.0\n","Reason: The score is 1.00 because the expected output is perfectly aligned with the information in the retrieval context. Great job!\n","\n","======================================================================\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 2 test case(s) in parallel: |██████████|100% (2/2) [Time Taken: 00:07,  4.00s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Contextual Recall Verbose Logs\n","**************************************************\n","\n","Verdicts:\n","[\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": \"The acronym 'AI' and its meaning 'Artificial Intelligence' is mentioned in the 2nd node: 'AI is an acronym for Artificial Intellence...'.\"\n","    },\n","    {\n","        \"verdict\": \"no\",\n","        \"reason\": \"The applications 'virtual assistants, robotics and autonomous vehicles' are not mentioned in any node of the retrieval context.\"\n","    }\n","]\n"," \n","Score: 0.5\n","Reason: The score is 0.50 because while the meaning of 'AI' as 'Artificial Intelligence' is supported by the 2nd node in retrieval context, the applications such as 'virtual assistants, robotics and autonomous vehicles' are not found in any node of the retrieval context.\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the expected output is perfectly aligned with the information in the retrieval context. Great job!, error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, including problem-solving and learning, with applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\n","  - context: None\n","  - retrieval context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Contextual Recall (score: 0.5, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because while the meaning of 'AI' as 'Artificial Intelligence' is supported by the 2nd node in retrieval context, the applications such as 'virtual assistants, robotics and autonomous vehicles' are not found in any node of the retrieval context., error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, including problem-solving and learning, with applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\n","  - context: None\n","  - retrieval context: ['NVIDIA makes chips for AI', 'AI is an acronym for Artificial Intellence']\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Contextual Recall: 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcae6817-0a1c-4ec6-ae51-7b2ca301be03","id":"13c3vhCQLRlt"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 1.0\n","Reason: The score is 1.00 because the expected output is perfectly aligned with the information in the retrieval context. Great job!\n"]}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[1].metrics_data[0].success)\n","print('Score:', result.test_results[1].metrics_data[0].score)\n","print('Reason:', result.test_results[1].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-bbC5jelN9v","outputId":"f86d6460-af92-4cb3-c90f-d6b8984cec82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 0.5\n","Reason: The score is 0.50 because while the meaning of 'AI' as 'Artificial Intelligence' is supported by the 2nd node in retrieval context, the applications such as 'virtual assistants, robotics and autonomous vehicles' are not found in any node of the retrieval context.\n"]}]},{"cell_type":"markdown","source":["## Contextual Relevancy\n","\n","The contextual relevancy metric measures the quality of your RAG pipeline's retriever by evaluating the overall relevance of the information presented in your `retrieval_context` for a given `input`.\n","\n","`deepeval`'s contextual relevancy metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n","\n","In `deepeval`, to use the ContextualRelevancyMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n","\n","- `input` : Input Query\n","- `actual_output` : Actual LLM Response (not used in the computation)\n","- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n","\n","\n","![](https://i.imgur.com/VLKoEsI.png)\n","\n","\n","\n"],"metadata":{"id":"SfHpMTVvSx7h"}},{"cell_type":"code","source":["query = \"What is AI?\"\n","response = rag_chain_w_sources.invoke(query)\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"89ad1a10-6299-4a0b-cea1-49bdbea2e0f5","id":"QI5H2AWqSx7h"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["### Example 1:"],"metadata":{"id":"45UdHqalSx7i"}},{"cell_type":"code","source":["retrieved_context = [doc.page_content for doc in response['context']]\n","retrieved_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2420dba1-4969-45df-923a-5ce5577f60af","id":"aOpExtxiSx7i"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["new_context = ['NVIDIA makes chips for AI', 'Google and Microsoft are battling out the market share for AI Chatbots'] + retrieved_context\n","new_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d4a3240-3268-4f5e-d61b-3f8e55c0d51a","id":"xyAtudlSSx7k"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['NVIDIA makes chips for AI',\n"," 'Google and Microsoft are battling out the market share for AI Chatbots',\n"," \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["from deepeval.test_case import LLMTestCase\n","from deepeval.metrics import ContextualRelevancyMetric\n","from deepeval import evaluate\n","\n","test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n","    expected_output=human_answer,\n","    retrieval_context=new_context\n",")\n","\n","metric = ContextualRelevancyMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    include_reason=True,\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"34468573-ef29-489e-8b4d-1cc27cca3714","id":"2_fQqaFUSx7l"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:10, 10.28s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Contextual Relevancy Verbose Logs\n","**************************************************\n","\n","Verdicts:\n","[\n","    {\n","        \"verdicts\": [\n","            {\n","                \"statement\": \"NVIDIA makes chips for AI\",\n","                \"verdict\": \"no\",\n","                \"reason\": \"The statement is about NVIDIA's business activities, not about what AI is.\"\n","            }\n","        ]\n","    },\n","    {\n","        \"verdicts\": [\n","            {\n","                \"statement\": \"Google and Microsoft are battling out the market share for AI Chatbots\",\n","                \"verdict\": \"no\",\n","                \"reason\": \"The statement 'Google and Microsoft are battling out the market share for AI Chatbots' is about companies' competition in AI chatbots, not about the definition or explanation of AI.\"\n","            }\n","        ]\n","    },\n","    {\n","        \"verdicts\": [\n","            {\n","                \"statement\": \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            },\n","            {\n","                \"statement\": \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            },\n","            {\n","                \"statement\": \"It's evolving rapidly with advancements in machine learning and deep learning.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            }\n","        ]\n","    },\n","    {\n","        \"verdicts\": [\n","            {\n","                \"statement\": \"NLP is a branch of AI that enables computers to understand, interpret, and generate human language.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            },\n","            {\n","                \"statement\": \"Techniques include tokenization, stemming, and sentiment analysis.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            },\n","            {\n","                \"statement\": \"Applications range from chatbots to language translation services.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            }\n","        ]\n","    },\n","    {\n","        \"verdicts\": [\n","            {\n","                \"statement\": \"Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            },\n","            {\n","                \"statement\": \"Algorithms analyze past data to make predictions or classify information.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            },\n","            {\n","                \"statement\": \"Popular applications include recommendation systems and image recognition.\",\n","                \"verdict\": \"yes\",\n","                \"reason\": null\n","            }\n","        ]\n","    }\n","]\n"," \n","Score: 0.8181818181818182\n","Reason: The score is 0.82 because the relevant statements provide a comprehensive overview of AI, covering its definition, applications, evolution, and techniques, despite some irrelevant context about business activities and market competition.\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Contextual Relevancy (score: 0.8181818181818182, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.82 because the relevant statements provide a comprehensive overview of AI, covering its definition, applications, evolution, and techniques, despite some irrelevant context about business activities and market competition., error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\n","  - context: None\n","  - retrieval context: ['NVIDIA makes chips for AI', 'Google and Microsoft are battling out the market share for AI Chatbots', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Contextual Relevancy: 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f73af640-72dd-4949-d462-c9219cd35168","id":"NnZIKnxmSx7l"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 0.8181818181818182\n","Reason: The score is 0.82 because the relevant statements provide a comprehensive overview of AI, covering its definition, applications, evolution, and techniques, despite some irrelevant context about business activities and market competition.\n"]}]},{"cell_type":"markdown","source":["# Generator Evaluation Metrics\n","\n","![](https://i.imgur.com/GaMHy7w.png)\n","\n","The generation step, which comes after retrieval, generally includes:\n","\n","- Building a prompt that combines the initial input with the context retrieved in the previous step.\n","- Feeding this prompt to your LLM, which produces the final generated response.\n","\n","\n","Key Metrics to Evaluate here include:\n","\n","- Answer Relevancy\n","- Faithfulness\n","- Hallucination Check\n","- Custom LLM as a Judge (G-Eval)"],"metadata":{"id":"ZlekplN_WC5A"}},{"cell_type":"markdown","source":["## LLM-based Answer Relevancy - DeepEval\n","\n","The answer relevancy metric measures the quality of your RAG pipeline's generator by evaluating how relevant the `actual_output` of your LLM application is compared to the provided `input`.\n","\n","`deepeval`'s answer relevancy metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n","\n","In `deepeval`, to use the AnswerRelevancyMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n","\n","- `input` : Input Query\n","- `actual_output` : Actual LLM Response\n","\n","\n","![](https://i.imgur.com/GbNSCFC.png)\n","\n","\n","\n","## Semantic Similarity based Answer Relevancy - RAGAS\n","\n","DeepEval has bindings to Ragas which enables us to use the RAGASAnswerRelevancyMetric which focuses on assessing how pertinent the generated answer is to the given query using cosine similarity. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy.\n","\n","![](https://i.imgur.com/vq1ytZ3.png)\n","\n","\n","\n"],"metadata":{"id":"bCsfBjF5l_sz"}},{"cell_type":"code","source":["query = \"What is AI?\"\n","response = rag_chain_w_sources.invoke(query)\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e32d6c8f-6484-4ba6-b9ee-2be7da70d804","id":"2nWBbl_3l_s0","executionInfo":{"status":"ok","timestamp":1734095873218,"user_tz":-330,"elapsed":1210,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["### Example - DeepEval:"],"metadata":{"id":"81EpPklYl_s1"}},{"cell_type":"code","source":["from deepeval.test_case import LLMTestCase\n","from deepeval.metrics import AnswerRelevancyMetric\n","from deepeval import evaluate\n","\n","test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n",")\n","\n","metric = AnswerRelevancyMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    include_reason=True,\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"78f646f0-bf75-4b67-b458-33346528fd59","id":"2klPvY0Al_s2","executionInfo":{"status":"ok","timestamp":1734095878632,"user_tz":-330,"elapsed":3675,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:03,  3.22s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Answer Relevancy Verbose Logs\n","**************************************************\n","\n","Statements:\n","[\n","    \"AI refers to machines mimicking human intelligence.\",\n","    \"Problem-solving and learning.\",\n","    \"Includes applications like virtual assistants, robotics, and autonomous vehicles.\"\n","] \n"," \n","Verdicts:\n","[\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": null\n","    },\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": null\n","    },\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": null\n","    }\n","]\n"," \n","Score: 1.0\n","Reason: The score is 1.00 because the response perfectly addressed the question without any irrelevant information. Great job!\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response perfectly addressed the question without any irrelevant information. Great job!, error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: None\n","  - context: None\n","  - retrieval context: None\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Answer Relevancy: 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JR5A3ZhPp6Dz","outputId":"552510ec-1894-4a35-bcca-e830f48b6fe9","executionInfo":{"status":"ok","timestamp":1734095878632,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 1.0\n","Reason: The score is 1.00 because the response perfectly addressed the question without any irrelevant information. Great job!\n"]}]},{"cell_type":"markdown","source":["### Example - RAGAS:"],"metadata":{"id":"9vZNbqkwx-Sj"}},{"cell_type":"code","source":["from deepeval.metrics.ragas import RAGASAnswerRelevancyMetric\n","\n","test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n",")\n","\n","metric = RAGASAnswerRelevancyMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    embeddings=OpenAIEmbeddings()\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":620,"referenced_widgets":["8890484b6c3e4018907b96b026510712","0a1982c87e18425a97c43a61c18f928b","d7e48662099b409baeb15177af124bb5","d3d8515a3b194fb3b1fdc820607a00bf","ce0f9b8f431246da93ebbe3c5cb8b026","28c6583c344341599988c3dad3070cc8","9d4be022d51847e8a1ccd0a9eb885de2","7614ca4667f948ccba8f980a1ae4722d","ab7499442d7648168ca9415bda596e05","ad467cc9f9884950ada71fbb95cfccbd","c5bd0a78f28749e39a63421f0da20446"]},"id":"VyssN8E4pv-U","outputId":"449d537e-ac37-47a7-cbbc-84b673781abc","executionInfo":{"status":"ok","timestamp":1734095893121,"user_tz":-330,"elapsed":5490,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mragas\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n","\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ragas</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n","<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating 1 test case(s) in parallel: |          |  0% (0/1) [Time Taken: 00:00, ?test case/s]"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8890484b6c3e4018907b96b026510712"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:04,  4.96s/test case]"]},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Answer Relevancy (ragas) (score: 0.9208862914051054, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: None\n","  - context: None\n","  - retrieval context: None\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Answer Relevancy (ragas): 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e878c34-3b16-4214-d5e8-d65dd47b5184","id":"WAubWCbzl_s3","executionInfo":{"status":"ok","timestamp":1734095897061,"user_tz":-330,"elapsed":316,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 0.9208862914051054\n","Reason: None\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tlZajG6R1EUc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Faithfulness\n","\n","The faithfulness metric measures the quality of your RAG pipeline's generator by evaluating whether the `actual_output` factually aligns with the contents of your `retrieval_context`.\n","\n","`deepeval`'s faithfulness metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n","\n","In `deepeval`, to use the FaithfulnessMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n","\n","- `input` : Input Query (not used in the computation)\n","- `actual_output` : Actual LLM Response\n","- `retrieval_context` : Top-N retrieved document chunks (nodes) from Vector DB\n","\n","\n","![](https://i.imgur.com/OCSFPTb.png)\n","\n","\n","\n"],"metadata":{"id":"JmdnS3rw1EhX"}},{"cell_type":"code","source":["query = \"What is AI?\"\n","response = rag_chain_w_sources.invoke(query)\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1fc21ab4-c554-4b6b-a732-a1e45c1503ce","id":"YPm0hd3m1EhY"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, including problem-solving and learning, with applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["### Example:"],"metadata":{"id":"tzoXGIqh1EhZ"}},{"cell_type":"code","source":["retrieved_context = [doc.page_content for doc in response['context']]\n","retrieved_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-p0SPQqW166X","outputId":"60e3f71c-95c1-48d6-a1a8-26a6f17501b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["from deepeval.test_case import LLMTestCase\n","from deepeval.metrics import FaithfulnessMetric\n","from deepeval import evaluate\n","\n","test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n","    retrieval_context=retrieved_context\n",")\n","\n","metric = FaithfulnessMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    include_reason=True,\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fd8d4b8a-df2f-462d-bbe7-f7e584519602","id":"3hw-CRSG1EhZ"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating 1 test case(s) in parallel: |          |  0% (0/1) [Time Taken: 00:00, ?test case/s]"]},{"output_type":"stream","name":"stdout","text":["None\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:06,  6.22s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Faithfulness Verbose Logs\n","**************************************************\n","\n","Truths (limit=None):\n","[\n","    \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning.\",\n","    \"AI includes applications like virtual assistants, robotics, and autonomous vehicles.\",\n","    \"AI is evolving rapidly with advancements in machine learning and deep learning.\",\n","    \"NLP is a branch of AI that enables computers to understand, interpret, and generate human language.\",\n","    \"NLP techniques include tokenization, stemming, and sentiment analysis.\",\n","    \"NLP applications range from chatbots to language translation services.\",\n","    \"Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data.\",\n","    \"Machine learning algorithms analyze past data to make predictions or classify information.\",\n","    \"Popular applications of machine learning include recommendation systems and image recognition.\"\n","] \n"," \n","Claims:\n","[\n","    \"AI refers to machines mimicking human intelligence, including problem-solving and learning.\",\n","    \"AI has applications like virtual assistants, robotics, and autonomous vehicles.\"\n","] \n"," \n","Verdicts:\n","[\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": null\n","    },\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": null\n","    }\n","]\n"," \n","Score: 1.0\n","Reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job!\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job!, error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, including problem-solving and learning, with applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: None\n","  - context: None\n","  - retrieval context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Faithfulness: 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"699f306e-344e-4ac3-ea64-b845d6e9bc82","id":"2kDPBfo71EhZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 1.0\n","Reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3OEaZBlf5Ijm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hallucination Check\n","\n","The hallucination metric determines whether your LLM generates factually correct information by comparing the `actual_output` to the provided (human ground truth) `context`.\n","\n","`deepeval`'s hallucination metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score using an LLM as a Judge.\n","\n","In `deepeval`, to use the HallucinationMetric, you'll have to provide the following arguments when creating an `LLMTestCase`:\n","\n","- `input` : Input Query (not used in the computation)\n","- `actual_output` : Actual LLM Response\n","- `context` : Human Ground Truth Context Document Chunks (Nodes)\n","\n","\n","![](https://i.imgur.com/qyVBKU2.png)\n","\n","\n","\n"],"metadata":{"id":"LrIyB4rA5I36"}},{"cell_type":"code","source":["query = \"What is AI?\"\n","response = rag_chain_w_sources.invoke(query)\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"85afd6d4-bfda-4e1f-bbd8-07266bce8ebc","id":"wGeeQFHy5I37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["### Example:"],"metadata":{"id":"L3uQFN3I5I37"}},{"cell_type":"code","source":["retrieved_context = [doc.page_content for doc in response['context']]\n","retrieved_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"199dcfe7-6521-42d3-e711-416f67f3b26d","id":"VGxjvNZM5I38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["human_ground_truth_context = [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n","                              \"Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.\"]\n","human_ground_truth_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pgjaKdKR6O4_","outputId":"addeede2-fd07-421e-83d1-4475e38b9c69"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["from deepeval.test_case import LLMTestCase\n","from deepeval.metrics import HallucinationMetric\n","from deepeval import evaluate\n","\n","test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=response['response'],\n","    context=human_ground_truth_context\n",")\n","\n","metric = HallucinationMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    include_reason=True,\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":909},"outputId":"85693856-dd93-46bb-87d5-bcc5abf0933a","id":"XXl6z6Cq5I38"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mHallucination Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Hallucination Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:03,  3.01s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Hallucination Verbose Logs\n","**************************************************\n","\n","Verdicts:\n","[\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": \"The actual output agrees with the provided context that AI refers to machines mimicking human intelligence and includes applications like virtual assistants, robotics, and autonomous vehicles.\"\n","    },\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": \"The actual output does not contradict the context. It covers the general concept of AI, which encompasses machine learning as one of its fields.\"\n","    }\n","]\n"," \n","Score: 0.0\n","Reason: The score is 0.00 because there are no contradictions between the actual output and the provided context, indicating perfect factual alignment.\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because there are no contradictions between the actual output and the provided context, indicating perfect factual alignment., error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.\n","  - expected output: None\n","  - context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n","  - retrieval context: None\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Hallucination: 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e12a69ed-48e4-49b7-fe0b-69572ab4b52d","id":"NNV-zh4f5I38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 0.0\n","Reason: The score is 0.00 because there are no contradictions between the actual output and the provided context, indicating perfect factual alignment.\n"]}]},{"cell_type":"code","source":["ai_response = 'AI refers to machines mimicking human intelligence to produce cyborgs and electric sheep'"],"metadata":{"id":"W6VU09PE6jOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=ai_response,\n","    context=human_ground_truth_context\n",")\n","\n","metric = HallucinationMetric(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    include_reason=True,\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":909},"id":"8jBVsZui6k_S","outputId":"a232645d-c59c-4264-da67-58283c77595e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mHallucination Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Hallucination Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:03,  3.20s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","Hallucination Verbose Logs\n","**************************************************\n","\n","Verdicts:\n","[\n","    {\n","        \"verdict\": \"no\",\n","        \"reason\": \"The actual output contradicts the provided context which states that artificial intelligence includes applications like virtual assistants, robotics, and autonomous vehicles, not specifically cyborgs and electric sheep.\"\n","    },\n","    {\n","        \"verdict\": \"yes\",\n","        \"reason\": \"The actual output is not in direct contradiction with the context which describes machine learning as a subset of artificial intelligence, as it does not specifically address the details of machine learning.\"\n","    }\n","]\n"," \n","Score: 0.5\n","Reason: The score is 0.50 because while the actual output does not directly contradict the context regarding machine learning, it incorrectly includes cyborgs and electric sheep as examples of artificial intelligence applications, which is not supported by the context.\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ✅ Hallucination (score: 0.5, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because while the actual output does not directly contradict the context regarding machine learning, it incorrectly includes cyborgs and electric sheep as examples of artificial intelligence applications, which is not supported by the context., error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence to produce cyborgs and electric sheep\n","  - expected output: None\n","  - context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n","  - retrieval context: None\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","Hallucination: 100.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sthkQ2_F6wwW","outputId":"bf71ad6e-ee28-485a-8bea-614cb9b279eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: True\n","Score: 0.5\n","Reason: The score is 0.50 because while the actual output does not directly contradict the context regarding machine learning, it incorrectly includes cyborgs and electric sheep as examples of artificial intelligence applications, which is not supported by the context.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"h0-E1OjJF3ak"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Custom LLM as a Judge (G-Eval)\n","\n","G-Eval is a framework that uses LLMs with chain-of-thoughts (CoT) to evaluate LLM outputs based on __ANY__ custom criteria.\n","\n","The G-Eval metric is the most versatile type of metric `deepeval` has to offer, and is capable of evaluating almost any use case with good accuracy.\n","\n","Here you are free to describe your custom evaluation process in detail using prompts in `evaluation_steps`.\n","\n","In `deepeval`, to use the GEval, you'll have to provide the following arguments when creating an `LLMTestCase`:\n","\n","- `input` : Input Query (not used in the computation)\n","- `actual_output` : Actual LLM Response\n","\n","You'll also need to supply any additional arguments such as `expected_output` and `context` if your evaluation criteria depends on these parameters.\n","\n","\n","\n","![](https://i.imgur.com/IuODLKQ.png)\n","\n","\n","\n"],"metadata":{"id":"amGTDvrCF3r8"}},{"cell_type":"code","source":["query = \"What is AI?\"\n","response = rag_chain_w_sources.invoke(query)\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"644174a0-6aba-40b3-c6ab-c9c74f1f420d","id":"-ZdDU9pDF3r8","executionInfo":{"status":"ok","timestamp":1734094010873,"user_tz":-330,"elapsed":1848,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n","  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n","  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n"," 'question': 'What is AI?',\n"," 'response': 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.'}"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["### Example:"],"metadata":{"id":"vLbxFHQ-F3r9"}},{"cell_type":"code","source":["retrieved_context = [doc.page_content for doc in response['context']]\n","retrieved_context"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"631cfcc6-047c-455a-c82b-2fa098238370","id":"h5kDpnMKF3r9","executionInfo":{"status":"ok","timestamp":1734094012121,"user_tz":-330,"elapsed":2,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\",\n"," 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.',\n"," 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["ai_response = response['response']\n","ai_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"eA88dIX2KClW","outputId":"26367487-75c1-4aad-a658-07e1368c4499","executionInfo":{"status":"ok","timestamp":1734094013406,"user_tz":-330,"elapsed":599,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like virtual assistants, robotics, and autonomous vehicles.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["ai_response = 'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like electric sheep and cyborg kittens'\n","ai_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"xk2n7gfnLGZD","outputId":"50f499dd-629d-45f3-ac73-bc867331fba8","executionInfo":{"status":"ok","timestamp":1734094014859,"user_tz":-330,"elapsed":3,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like electric sheep and cyborg kittens'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["human_answer = \"\"\"AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\"\"\"\n","human_answer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"InzJ2ro184f-","outputId":"ac74d394-22ec-477c-cfe3-77729421011e","executionInfo":{"status":"ok","timestamp":1734094016313,"user_tz":-330,"elapsed":3,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'AI, also known as Artificial Intelligence is used to build complex systems for applications\\n                  like virtual assistants, robotics and autonomous vehicles.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["from deepeval.test_case import LLMTestCase\n","from deepeval.metrics import GEval\n","from deepeval import evaluate\n","from deepeval.test_case import LLMTestCaseParams\n","\n","test_case = LLMTestCase(\n","    input=response['question'],\n","    actual_output=ai_response,\n","    expected_output=human_answer,\n","    retrieval_context=retrieved_context\n",")\n","\n","metric = GEval(\n","    threshold=0.5,\n","    model=\"gpt-4o\",\n","    name=\"RAG Fact Checker\",\n","    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n","    evaluation_steps=[\n","        \"Create a list of statements from 'actual output'\",\n","        \"Validate if they are relevant and answers the given question in 'input', penalize if any statements are irrelevant\",\n","        \"Also Validate if they exist in 'expected output', penalize if any statements are missing or factually wrong\",\n","        \"Also validate if these statements are grounded in the 'retrieval context' and penalize if they are missing or factually wrong\",\n","        \"Finally also penalize if any statements seem to be invented or made up and do not make sense factually given the 'input' and 'retrieval context'\"\n","    ],\n","    evaluation_params=[LLMTestCaseParams.INPUT,\n","                       LLMTestCaseParams.ACTUAL_OUTPUT,\n","                       LLMTestCaseParams.EXPECTED_OUTPUT,\n","                       LLMTestCaseParams.RETRIEVAL_CONTEXT],\n","    verbose_mode=True\n",")\n","\n","result = evaluate([test_case], [metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":943},"outputId":"8f6fe87a-d5af-477d-f06f-0482cf1d5005","id":"Hl2PbM8ZF3r-"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRAG Fact Checker \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n","\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">RAG Fact Checker </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n","<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:02,  2.80s/test case]"]},{"output_type":"stream","name":"stdout","text":["**************************************************\n","RAG Fact Checker (GEval) Verbose Logs\n","**************************************************\n","\n","Criteria:\n","None \n"," \n","Evaluation Steps:\n","[\n","    \"Create a list of statements from 'actual output'\",\n","    \"Validate if they are relevant and answers the given question in 'input', penalize if any statements are irrelevant\",\n","    \"Also Validate if they exist in 'expected output', penalize if any statements are missing or factually wrong\",\n","    \"Also validate if these statements are grounded in the 'retrieval context' and penalize if they are missing or factually wrong\",\n","    \"Finally also penalize if any statements seem to be invented or made up and do not make sense factually given the 'input' and 'retrieval context'\"\n","]\n"," \n","Score: 0.39317121956294554\n","Reason: The actual output correctly states AI involves machines mimicking human intelligence, which is relevant to the input and grounded in the retrieval context. However, it mentions irrelevant and unsupported examples like 'electric sheep' and 'cyborg kittens', which are not present in the expected output or retrieval context. Expected applications like virtual assistants and robotics are missing in the actual output.\n","\n","======================================================================\n","\n","======================================================================\n","\n","Metrics Summary\n","\n","  - ❌ RAG Fact Checker (GEval) (score: 0.39317121956294554, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output correctly states AI involves machines mimicking human intelligence, which is relevant to the input and grounded in the retrieval context. However, it mentions irrelevant and unsupported examples like 'electric sheep' and 'cyborg kittens', which are not present in the expected output or retrieval context. Expected applications like virtual assistants and robotics are missing in the actual output., error: None)\n","\n","For test case:\n","\n","  - input: What is AI?\n","  - actual output: AI refers to machines mimicking human intelligence, such as problem-solving and learning, and includes applications like electric sheep and cyborg kittens\n","  - expected output: AI, also known as Artificial Intelligence is used to build complex systems for applications\n","                  like virtual assistants, robotics and autonomous vehicles.\n","  - context: None\n","  - retrieval context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n","\n","======================================================================\n","\n","Overall Metric Pass Rates\n","\n","RAG Fact Checker (GEval): 0.00% pass rate\n","\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n","‼️  Friendly reminder 😇: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n","instead.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print('Sucess:', result.test_results[0].metrics_data[0].success)\n","print('Score:', result.test_results[0].metrics_data[0].score)\n","print('Reason:', result.test_results[0].metrics_data[0].reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8667470e-21da-4676-dbb5-5de6d82e2284","id":"7UJYPsYlF3r-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sucess: False\n","Score: 0.39317121956294554\n","Reason: The actual output correctly states AI involves machines mimicking human intelligence, which is relevant to the input and grounded in the retrieval context. However, it mentions irrelevant and unsupported examples like 'electric sheep' and 'cyborg kittens', which are not present in the expected output or retrieval context. Expected applications like virtual assistants and robotics are missing in the actual output.\n"]}]}]}